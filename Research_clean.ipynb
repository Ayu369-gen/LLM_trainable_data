{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayu369-gen/LLM_trainable_data/blob/main/Research_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf4llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFC4Ohz4XeQl",
        "outputId": "0408e969-ca69-4163-83a0-e31d2aa05aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.0.24-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pymupdf>=1.25.5 (from pymupdf4llm)\n",
            "  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf4llm-0.0.24-py3-none-any.whl (28 kB)\n",
            "Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf, pymupdf4llm\n",
            "Successfully installed pymupdf-1.26.0 pymupdf4llm-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_api_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-eqt_OYXt1n",
        "outputId": "5de7f3fd-efd2-450f-ee42-5d34b92d0705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_api_client\n",
            "  Downloading llama_api_client-0.1.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from llama_api_client) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->llama_api_client) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->llama_api_client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->llama_api_client) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_api_client) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->llama_api_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->llama_api_client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->llama_api_client) (0.4.1)\n",
            "Downloading llama_api_client-0.1.1-py3-none-any.whl (83 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/83.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: llama_api_client\n",
            "Successfully installed llama_api_client-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "HVj6V5kmUhmG",
        "outputId": "8cc239eb-2297-4e54-b77e-cf366cc9ef97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select PDF files to process...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "no display name and no $DISPLAY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-837357688359>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-837357688359>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please select PDF files to process...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0minput_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_pdf_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-837357688359>\u001b[0m in \u001b[0;36mselect_pdf_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_pdf_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"Open a file dialog for selecting PDF files.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "from typing import Optional, List\n",
        "from pathlib import Path\n",
        "import fitz  # PyMuPDF\n",
        "from pymupdf4llm import to_markdown\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up the Llama API client\n",
        "try:\n",
        "    from llama_api_client import LlamaAPIClient\n",
        "    os.environ[\"LLAMA_API_KEY\"] = \"YOUR_LLAMA_API\"\n",
        "    client = LlamaAPIClient(\n",
        "        api_key=os.environ.get(\"LLAMA_API_KEY\"),\n",
        "        base_url=\"https://api.llama.com/v1/\",\n",
        "    )\n",
        "except ImportError:\n",
        "    raise ImportError(\"llama_api_client is required. Please install it using 'pip install llama_api_client'.\")\n",
        "\n",
        "def select_pdf_files() -> List[str]:\n",
        "    \"\"\"Open a file dialog for selecting PDF files.\"\"\"\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()\n",
        "\n",
        "    file_paths = filedialog.askopenfilenames(\n",
        "        title=\"Select PDF files\",\n",
        "        filetypes=[(\"PDF files\", \"*.pdf\")]\n",
        "    )\n",
        "\n",
        "    if not file_paths:\n",
        "        messagebox.showinfo(\"No Selection\", \"No files were selected.\")\n",
        "        return []\n",
        "\n",
        "    return list(file_paths)\n",
        "\n",
        "def download_jsonl_files(jsonl_dir: str, download_dir: str) -> None:\n",
        "    \"\"\"Copy processed JSONL files to the download directory.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(download_dir, exist_ok=True)\n",
        "        for file in os.listdir(jsonl_dir):\n",
        "            if file.endswith('.jsonl'):\n",
        "                src_path = os.path.join(jsonl_dir, file)\n",
        "                dst_path = os.path.join(download_dir, file)\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "        print(f\"\\nFiles have been downloaded to: {download_dir}\")\n",
        "        messagebox.showinfo(\"Download Complete\", f\"Files have been downloaded to:\\n{download_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading files: {e}\")\n",
        "        messagebox.showerror(\"Download Error\", f\"Error downloading files: {e}\")\n",
        "\n",
        "def extract_metadata(pdf_path: str) -> dict:\n",
        "    \"\"\"Extract metadata from PDF (title, authors, year).\"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        metadata = doc.metadata\n",
        "        doc.close()\n",
        "\n",
        "        return {\n",
        "            \"title\": metadata.get(\"title\", \"\"),\n",
        "            \"authors\": metadata.get(\"author\", \"\"),\n",
        "            \"creation_date\": metadata.get(\"creationDate\", \"\"),\n",
        "            \"keywords\": metadata.get(\"keywords\", \"\")\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting metadata: {e}\")\n",
        "        return {}\n",
        "\n",
        "def convert_pdf_to_text(pdf_path: str, output_dir: str) -> Optional[str]:\n",
        "    \"\"\"Convert a PDF file to markdown text using pymupdf4llm.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        pdf_name = Path(pdf_path).stem\n",
        "        md_path = os.path.join(output_dir, f\"{pdf_name}_pymupdf4llm.md\")\n",
        "        print(f\"Converting {pdf_path} to markdown...\")\n",
        "        markdown_text = to_markdown(pdf_path)\n",
        "        print(f\"Markdown text length: {len(markdown_text)}\")\n",
        "        with open(md_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(markdown_text)\n",
        "        print(f\"Markdown file saved to {md_path}\")\n",
        "        return md_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting PDF to markdown: {e}\")\n",
        "        return None\n",
        "\n",
        "def chunk_text(text: str, max_chunk_size: int = 4000) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split text into chunks while preserving research paper structure.\n",
        "    Attempts to keep sections (Abstract, Methods, etc.) together.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_section = \"\"\n",
        "\n",
        "    # Common research paper sections\n",
        "    section_headers = [\n",
        "        r'^#{1,3}\\s*Abstract\\s*$',\n",
        "        r'^#{1,3}\\s*Introduction\\s*$',\n",
        "        r'^#{1,3}\\s*Methods\\s*$',\n",
        "        r'^#{1,3}\\s*Materials and Methods\\s*$',\n",
        "        r'^#{1,3}\\s*Results\\s*$',\n",
        "        r'^#{1,3}\\s*Discussion\\s*$',\n",
        "        r'^#{1,3}\\s*Conclusion\\s*$',\n",
        "        r'^#{1,3}\\s*References\\s*$',\n",
        "        r'^#{1,3}\\s*Acknowledgements\\s*$'\n",
        "    ]\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        # Check if line is a section header\n",
        "        is_section = any(re.match(header, line, re.IGNORECASE) for header in section_headers)\n",
        "\n",
        "        if is_section:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = line + '\\n'\n",
        "            current_section = line\n",
        "        else:\n",
        "            if len(current_chunk) + len(line) + 1 <= max_chunk_size:\n",
        "                current_chunk += line + '\\n'\n",
        "            else:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                current_chunk = (current_section + '\\n' + line + '\\n') if current_section else (line + '\\n')\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def query_llama_api(text: str, prompt: str) -> Optional[str]:\n",
        "    \"\"\"Send text to the Llama API with a prompt and return the response.\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert in marine science and aquaculture research paper analysis. Extract ONLY the plain text content related to marine science and aquaculture. Remove all formatting, headers, numbers, and special characters. Output should be clean, continuous text without any structural elements.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n### Input Text:\\n{text}\"}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            top_p=0.9\n",
        "        )\n",
        "        response_text = response.completion_message.content.text.strip()\n",
        "        return response_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying API: {e}\")\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert in marine science and aquaculture research paper analysis. Extract ONLY the plain text content related to marine science and aquaculture. Remove all formatting, headers, numbers, and special characters. Output should be clean, continuous text without any structural elements.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n### Input Text:\\n{text}\"}\n",
        "                ]\n",
        "            )\n",
        "            response_text = response.completion_message.content.text.strip()\n",
        "            return response_text\n",
        "        except Exception as fallback_e:\n",
        "            print(f\"Fallback API call failed: {fallback_e}\")\n",
        "            return None\n",
        "\n",
        "def process_text_chunk(chunk: str, prompt: str) -> Optional[List[str]]:\n",
        "    \"\"\"Process a single chunk of text through the Llama API.\"\"\"\n",
        "    cleaned_content = query_llama_api(chunk, prompt)\n",
        "    if not cleaned_content:\n",
        "        return None\n",
        "\n",
        "    # Post-process to clean up extra whitespace and normalize newlines\n",
        "    cleaned_content = re.sub(r'\\n\\s*\\n+', '\\n\\n', cleaned_content).strip()\n",
        "\n",
        "    # Split content into continuous text segments\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "\n",
        "    for line in cleaned_content.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Skip reference-like lines (e.g., \"[1]\", \"(Smith et al., 2020)\")\n",
        "        if re.match(r'^\\[\\d+\\]$', line) or re.match(r'^\\(.*,\\s*\\d{4}\\)$', line):\n",
        "            continue\n",
        "\n",
        "        current_segment.append(line)\n",
        "\n",
        "    # Add the segment\n",
        "    if current_segment:\n",
        "        segment_text = ' '.join(current_segment)\n",
        "        if segment_text.strip():\n",
        "            segments.append(segment_text)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def clean_research_paper(input_file: str, output_file: str, metadata: dict) -> None:\n",
        "    \"\"\"\n",
        "    Process aquaculture research paper content while retaining scientific information.\n",
        "    Output includes metadata and is saved in JSONL format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        return\n",
        "    except UnicodeDecodeError:\n",
        "        print(\"Error: File encoding issue. Ensure the file is UTF-8 encoded.\")\n",
        "        return\n",
        "\n",
        "    prompt = \"\"\"Extract ONLY the plain text content related to marine science and aquaculture from the following research paper text. Remove all formatting, headers, and structural elements.\n",
        "\n",
        "**Content to Extract:**\n",
        "- Marine biology and ecology\n",
        "- Aquaculture systems and practices\n",
        "- Fisheries management\n",
        "- Marine conservation\n",
        "- Oceanography and marine ecosystems\n",
        "- Marine species biology and behavior\n",
        "- Aquaculture technology and innovations\n",
        "- Marine resource management\n",
        "- Water quality and environmental parameters\n",
        "- Marine food production systems\n",
        "- Experimental methods and results\n",
        "- Statistical analyses\n",
        "- Scientific observations and conclusions\n",
        "\n",
        "**Output Rules:**\n",
        "1. Output ONLY plain text content\n",
        "2. Remove all headers, subheaders, and section titles\n",
        "3. Remove all numerical markings, bullet points, and reference citations (e.g., [1], (Smith et al., 2020))\n",
        "4. Remove all formatting (bold, italic, etc.)\n",
        "5. Remove all special characters and symbols except basic punctuation\n",
        "6. Convert content into continuous paragraphs\n",
        "7. Maintain proper sentence structure and punctuation\n",
        "8. Preserve all scientific terms, technical descriptions, and data\n",
        "9. Preserve the meaning and context of the content\n",
        "10. Exclude reference lists, acknowledgments, and non-scientific content\n",
        "11. DO NOT include any meta-instructions or processing commentary\n",
        "12. Preserve numerical data and statistical results\n",
        "13. Maintain methodology descriptions\n",
        "14. Keep species names and technical terms intact\n",
        "\n",
        "Remember: Your output should be clean, continuous text without any structural elements or formatting.\"\"\"\n",
        "\n",
        "    chunks = chunk_text(content)\n",
        "    all_segments = []\n",
        "\n",
        "    print(f\"Processing {len(chunks)} chunks from {input_file}...\")\n",
        "    for i, chunk in enumerate(chunks, 1):\n",
        "        print(f\"Processing chunk {i}/{len(chunks)}...\")\n",
        "        segments = process_text_chunk(chunk, prompt)\n",
        "        if segments:\n",
        "            all_segments.extend(segments)\n",
        "\n",
        "    try:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            for segment in all_segments:\n",
        "                json_obj = {\n",
        "                    \"text\": segment,\n",
        "                    \"metadata\": metadata\n",
        "                }\n",
        "                file.write(json.dumps(json_obj) + '\\n')\n",
        "        print(f\"Cleaned content saved to '{output_file}' in JSONL format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def process_multiple_files(input_files: List[str], output_dir: str) -> None:\n",
        "    \"\"\"Process multiple input files and save the cleaned versions.\"\"\"\n",
        "    md_dir = os.path.join(output_dir, 'markdown')\n",
        "    jsonl_dir = os.path.join(output_dir, 'jsonl')\n",
        "    os.makedirs(md_dir, exist_ok=True)\n",
        "    os.makedirs(jsonl_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Selected files:\", input_files)\n",
        "\n",
        "    for input_file in input_files:\n",
        "        input_path = Path(input_file)\n",
        "\n",
        "        # Extract metadata\n",
        "        metadata = extract_metadata(input_file) if input_path.suffix.lower() == '.pdf' else {}\n",
        "\n",
        "        # Convert PDF to markdown\n",
        "        if input_path.suffix.lower() == '.pdf':\n",
        "            md_file = convert_pdf_to_text(input_file, md_dir)\n",
        "            if not md_file:\n",
        "                print(f\"Skipping {input_file} due to conversion error\")\n",
        "                continue\n",
        "        else:\n",
        "            md_file = input_file\n",
        "\n",
        "        # Process the markdown file\n",
        "        output_file = os.path.join(jsonl_dir, f\"cleaned_{input_path.stem}.jsonl\")\n",
        "        print(f\"\\nProcessing file: {md_file}\")\n",
        "        clean_research_paper(md_file, output_file, metadata)\n",
        "\n",
        "def main():\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = f'cleaned_output_{timestamp}'\n",
        "\n",
        "    print(\"Please select PDF files to process...\")\n",
        "    input_files = select_pdf_files()\n",
        "\n",
        "    if not input_files:\n",
        "        print(\"No files selected. Exiting...\")\n",
        "        return\n",
        "\n",
        "    process_multiple_files(input_files, output_dir)\n",
        "\n",
        "    jsonl_dir = os.path.join(output_dir, 'jsonl')\n",
        "    download_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", f\"processed_jsonl_{timestamp}\")\n",
        "    download_jsonl_files(jsonl_dir, download_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "from typing import Optional, List\n",
        "from pathlib import Path\n",
        "import fitz  # PyMuPDF\n",
        "from pymupdf4llm import to_markdown\n",
        "# Remove tkinter imports\n",
        "# import tkinter as tk\n",
        "# from tkinter import filedialog, messagebox\n",
        "from datetime import datetime\n",
        "\n",
        "# Import Colab file upload utilities\n",
        "from google.colab import files\n",
        "\n",
        "# Set up the Llama API client\n",
        "try:\n",
        "    from llama_api_client import LlamaAPIClient\n",
        "    os.environ[\"LLAMA_API_KEY\"] = \"LLM|461707323672851|W1xFA7FgVN58q0ep2JFTPyFyTKQ\"\n",
        "    client = LlamaAPIClient(\n",
        "        api_key=os.environ.get(\"LLAMA_API_KEY\"),\n",
        "        base_url=\"https://api.llama.com/v1/\",\n",
        "    )\n",
        "except ImportError:\n",
        "    raise ImportError(\"llama_api_client is required. Please install it using 'pip install llama_api_client'.\")\n",
        "\n",
        "# Remove the select_pdf_files function\n",
        "\n",
        "def download_jsonl_files(jsonl_dir: str, download_dir: str) -> None:\n",
        "    \"\"\"Copy processed JSONL files to the download directory and offer download in Colab.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(download_dir, exist_ok=True)\n",
        "        print(f\"\\nCopying files to download directory: {download_dir}\")\n",
        "        for file in os.listdir(jsonl_dir):\n",
        "            if file.endswith('.jsonl'):\n",
        "                src_path = os.path.join(jsonl_dir, file)\n",
        "                dst_path = os.path.join(download_dir, file)\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "        print(f\"Files prepared for download in: {download_dir}\")\n",
        "\n",
        "        # Offer download in Colab\n",
        "        print(\"\\nOffering files for download:\")\n",
        "        for file_name in os.listdir(download_dir):\n",
        "            if file_name.endswith('.jsonl'):\n",
        "                file_path = os.path.join(download_dir, file_name)\n",
        "                try:\n",
        "                    files.download(file_path)\n",
        "                    print(f\" - Downloaded {file_name}\")\n",
        "                except Exception as download_error:\n",
        "                    print(f\" - Failed to download {file_name}: {download_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during file processing or download preparation: {e}\")\n",
        "\n",
        "\n",
        "def extract_metadata(pdf_path: str) -> dict:\n",
        "    \"\"\"Extract metadata from PDF (title, authors, year).\"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        metadata = doc.metadata\n",
        "        doc.close()\n",
        "\n",
        "        return {\n",
        "            \"title\": metadata.get(\"title\", \"\"),\n",
        "            \"authors\": metadata.get(\"author\", \"\"),\n",
        "            \"creation_date\": metadata.get(\"creationDate\", \"\"),\n",
        "            \"keywords\": metadata.get(\"keywords\", \"\")\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting metadata: {e}\")\n",
        "        return {}\n",
        "\n",
        "def convert_pdf_to_text(pdf_path: str, output_dir: str) -> Optional[str]:\n",
        "    \"\"\"Convert a PDF file to markdown text using pymupdf4llm.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        pdf_name = Path(pdf_path).stem\n",
        "        md_path = os.path.join(output_dir, f\"{pdf_name}_pymupdf4llm.md\")\n",
        "        print(f\"Converting {pdf_path} to markdown...\")\n",
        "        markdown_text = to_markdown(pdf_path)\n",
        "        print(f\"Markdown text length: {len(markdown_text)}\")\n",
        "        with open(md_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(markdown_text)\n",
        "        print(f\"Markdown file saved to {md_path}\")\n",
        "        return md_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting PDF to markdown: {e}\")\n",
        "        return None\n",
        "\n",
        "def chunk_text(text: str, max_chunk_size: int = 4000) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split text into chunks while preserving research paper structure.\n",
        "    Attempts to keep sections (Abstract, Methods, etc.) together.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_section = \"\"\n",
        "\n",
        "    # Common research paper sections\n",
        "    section_headers = [\n",
        "        r'^#{1,3}\\s*Abstract\\s*$',\n",
        "        r'^#{1,3}\\s*Introduction\\s*$',\n",
        "        r'^#{1,3}\\s*Methods\\s*$',\n",
        "        r'^#{1,3}\\s*Materials and Methods\\s*$',\n",
        "        r'^#{1,3}\\s*Results\\s*$',\n",
        "        r'^#{1,3}\\s*Discussion\\s*$',\n",
        "        r'^#{1,3}\\s*Conclusion\\s*$',\n",
        "        r'^#{1,3}\\s*References\\s*$',\n",
        "        r'^#{1,3}\\s*Acknowledgements\\s*$'\n",
        "    ]\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        # Check if line is a section header\n",
        "        is_section = any(re.match(header, line, re.IGNORECASE) for header in section_headers)\n",
        "\n",
        "        if is_section:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = line + '\\n'\n",
        "            current_section = line\n",
        "        else:\n",
        "            if len(current_chunk) + len(line) + 1 <= max_chunk_size:\n",
        "                current_chunk += line + '\\n'\n",
        "            else:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                current_chunk = (current_section + '\\n' + line + '\\n') if current_section else (line + '\\n')\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def query_llama_api(text: str, prompt: str) -> Optional[str]:\n",
        "    \"\"\"Send text to the Llama API with a prompt and return the response.\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert in marine science and aquaculture research paper analysis. Extract ONLY the plain text content related to marine science and aquaculture. Remove all formatting, headers, numbers, and special characters. Output should be clean, continuous text without any structural elements.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n### Input Text:\\n{text}\"}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            top_p=0.9\n",
        "        )\n",
        "        response_text = response.completion_message.content.text.strip()\n",
        "        return response_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying API: {e}\")\n",
        "        try:\n",
        "            # Fallback with default parameters if specific ones cause issues\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert in marine science and aquaculture research paper analysis. Extract ONLY the plain text content related to marine science and aquaculture. Remove all formatting, headers, numbers, and special characters. Output should be clean, continuous text without any structural elements.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n### Input Text:\\n{text}\"}\n",
        "                ]\n",
        "            )\n",
        "            response_text = response.completion_message.content.text.strip()\n",
        "            return response_text\n",
        "        except Exception as fallback_e:\n",
        "            print(f\"Fallback API call failed: {fallback_e}\")\n",
        "            return None\n",
        "\n",
        "def process_text_chunk(chunk: str, prompt: str) -> Optional[List[str]]:\n",
        "    \"\"\"Process a single chunk of text through the Llama API.\"\"\"\n",
        "    cleaned_content = query_llama_api(chunk, prompt)\n",
        "    if not cleaned_content:\n",
        "        return None\n",
        "\n",
        "    # Post-process to clean up extra whitespace and normalize newlines\n",
        "    cleaned_content = re.sub(r'\\n\\s*\\n+', '\\n\\n', cleaned_content).strip()\n",
        "\n",
        "    # Split content into continuous text segments\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "\n",
        "    for line in cleaned_content.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Skip reference-like lines (e.g., \"[1]\", \"(Smith et al., 2020)\")\n",
        "        # Be careful with regex to avoid false positives on valid text\n",
        "        if re.match(r'^\\[\\d+\\]$', line) or re.match(r'^\\([^)]+,\\s*\\d{4}\\)$', line): # Improved regex for year citations\n",
        "            continue\n",
        "\n",
        "        current_segment.append(line)\n",
        "\n",
        "    # Add the segment\n",
        "    if current_segment:\n",
        "        segment_text = ' '.join(current_segment)\n",
        "        if segment_text.strip():\n",
        "            segments.append(segment_text)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def clean_research_paper(input_file: str, output_file: str, metadata: dict) -> None:\n",
        "    \"\"\"\n",
        "    Process aquaculture research paper content while retaining scientific information.\n",
        "    Output includes metadata and is saved in JSONL format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        return\n",
        "    except UnicodeDecodeError:\n",
        "        print(\"Error: File encoding issue. Ensure the file is UTF-8 encoded.\")\n",
        "        return\n",
        "\n",
        "    prompt = \"\"\"Extract ONLY the plain text content related to marine science and aquaculture from the following research paper text. Remove all formatting, headers, and structural elements.\n",
        "\n",
        "**Content to Extract:**\n",
        "- Marine biology and ecology\n",
        "- Aquaculture systems and practices\n",
        "- Fisheries management\n",
        "- Marine conservation\n",
        "- Oceanography and marine ecosystems\n",
        "- Marine species biology and behavior\n",
        "- Aquaculture technology and innovations\n",
        "- Marine resource management\n",
        "- Water quality and environmental parameters\n",
        "- Marine food production systems\n",
        "- Experimental methods and results\n",
        "- Statistical analyses\n",
        "- Scientific observations and conclusions\n",
        "\n",
        "**Output Rules:**\n",
        "1. Output ONLY plain text content\n",
        "2. Remove all headers, subheaders, and section titles\n",
        "3. Remove all numerical markings, bullet points, and reference citations (e.g., [1], (Smith et al., 2020))\n",
        "4. Remove all formatting (bold, italic, etc.)\n",
        "5. Remove all special characters and symbols except basic punctuation\n",
        "6. Convert content into continuous paragraphs\n",
        "7. Maintain proper sentence structure and punctuation\n",
        "8. Preserve all scientific terms, technical descriptions, and data\n",
        "9. Preserve the meaning and context of the content\n",
        "10. Exclude reference lists, acknowledgments, and non-scientific content\n",
        "11. DO NOT include any meta-instructions or processing commentary\n",
        "12. Preserve numerical data and statistical results\n",
        "13. Maintain methodology descriptions\n",
        "14. Keep species names and technical terms intact\n",
        "\n",
        "Remember: Your output should be clean, continuous text without any structural elements or formatting.\"\"\"\n",
        "\n",
        "    chunks = chunk_text(content)\n",
        "    all_segments = []\n",
        "\n",
        "    print(f\"Processing {len(chunks)} chunks from {input_file}...\")\n",
        "    for i, chunk in enumerate(chunks, 1):\n",
        "        print(f\"Processing chunk {i}/{len(chunks)}...\")\n",
        "        segments = process_text_chunk(chunk, prompt)\n",
        "        if segments:\n",
        "            all_segments.extend(segments)\n",
        "\n",
        "    try:\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            for segment in all_segments:\n",
        "                json_obj = {\n",
        "                    \"text\": segment,\n",
        "                    \"metadata\": metadata\n",
        "                }\n",
        "                file.write(json.dumps(json_obj) + '\\n')\n",
        "        print(f\"Cleaned content saved to '{output_file}' in JSONL format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def process_multiple_files(input_files: List[str], output_dir: str) -> None:\n",
        "    \"\"\"Process multiple input files and save the cleaned versions.\"\"\"\n",
        "    md_dir = os.path.join(output_dir, 'markdown')\n",
        "    jsonl_dir = os.path.join(output_dir, 'jsonl')\n",
        "    os.makedirs(md_dir, exist_ok=True)\n",
        "    os.makedirs(jsonl_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Selected files:\", input_files)\n",
        "\n",
        "    for input_file in input_files:\n",
        "        input_path = Path(input_file)\n",
        "\n",
        "        # Extract metadata\n",
        "        metadata = extract_metadata(input_file) if input_path.suffix.lower() == '.pdf' else {}\n",
        "\n",
        "        # Convert PDF to markdown\n",
        "        if input_path.suffix.lower() == '.pdf':\n",
        "            md_file = convert_pdf_to_text(input_file, md_dir)\n",
        "            if not md_file:\n",
        "                print(f\"Skipping {input_file} due to conversion error\")\n",
        "                continue\n",
        "        else:\n",
        "            # If the input file is already markdown, just use it\n",
        "            md_file = input_file\n",
        "\n",
        "        # Process the markdown file\n",
        "        output_file = os.path.join(jsonl_dir, f\"cleaned_{input_path.stem}.jsonl\")\n",
        "        print(f\"\\nProcessing file: {md_file}\")\n",
        "        clean_research_paper(md_file, output_file, metadata)\n",
        "\n",
        "def main():\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = f'cleaned_output_{timestamp}'\n",
        "    jsonl_dir = os.path.join(output_dir, 'jsonl')\n",
        "    download_dir = os.path.join(\"downloads\", f\"processed_jsonl_{timestamp}\") # Use a relative path for Colab\n",
        "\n",
        "    print(\"Please upload your PDF files.\")\n",
        "    # Use Colab's file upload widget\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # 'uploaded' is a dictionary {filename: content}\n",
        "    # We need to save these files to the Colab environment first\n",
        "    input_files = []\n",
        "    upload_dir = \"uploaded_pdfs\" # Directory to save uploaded files\n",
        "    os.makedirs(upload_dir, exist_ok=True)\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No files uploaded. Exiting...\")\n",
        "        return\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        file_path = os.path.join(upload_dir, filename)\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(content)\n",
        "        input_files.append(file_path)\n",
        "        print(f\"Saved uploaded file: {file_path}\")\n",
        "\n",
        "\n",
        "    if not input_files:\n",
        "        print(\"No files found in the upload directory. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Process the uploaded files\n",
        "    process_multiple_files(input_files, output_dir)\n",
        "\n",
        "    # Offer the resulting JSONL files for download via Colab's download function\n",
        "    download_jsonl_files(jsonl_dir, download_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9M-bhmt2Km6_",
        "outputId": "13a18ff3-4429-4769-a2fd-e38622a2f427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e8ad1f13-e83e-4d1d-b891-bf3eb892c6fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e8ad1f13-e83e-4d1d-b891-bf3eb892c6fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving animals-13-01250.pdf to animals-13-01250.pdf\n",
            "Saving biology-12-00092.pdf to biology-12-00092.pdf\n",
            "Saving Blake_2010_Bioinspir._Biomim._5_030201 (1).pdf to Blake_2010_Bioinspir._Biomim._5_030201 (1).pdf\n",
            "Saving Blake_2010_Bioinspir._Biomim._5_030201.pdf to Blake_2010_Bioinspir._Biomim._5_030201.pdf\n",
            "Saving Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.pdf to Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.pdf\n",
            "Saving fcell-07-00013.pdf to fcell-07-00013.pdf\n",
            "Saving fgene-14-1183637.pdf to fgene-14-1183637.pdf\n",
            "Saving Fish_2020_Bioinspir._Biomim._15_060401.pdf to Fish_2020_Bioinspir._Biomim._15_060401.pdf\n",
            "Saving fmars-09-924475.pdf to fmars-09-924475.pdf\n",
            "Saving fmicb-12-567408.pdf to fmicb-12-567408.pdf\n",
            "Saving Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.pdf to Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.pdf\n",
            "Saving Genome Res.-2015-Varshney-1030-42.pdf to Genome Res.-2015-Varshney-1030-42.pdf\n",
            "Saving ieam1530.pdf to ieam1530.pdf\n",
            "Saving ijms-25-09299-v2.pdf to ijms-25-09299-v2.pdf\n",
            "Saving jeb236802.pdf to jeb236802.pdf\n",
            "Saving nclimate1616.pdf to nclimate1616.pdf\n",
            "Saving PIIS1534580715000751.pdf to PIIS1534580715000751.pdf\n",
            "Saving PIIS1534580719308135 (1).pdf to PIIS1534580719308135 (1).pdf\n",
            "Saving PIIS1534580719308135.pdf to PIIS1534580719308135.pdf\n",
            "Saving s41467-017-00175-6.pdf to s41467-017-00175-6.pdf\n",
            "Saving srep08841.pdf to srep08841.pdf\n",
            "Saving 1-s2.0-S1046202316302833-main.pdf to 1-s2.0-S1046202316302833-main.pdf\n",
            "Saving 4982.pdf to 4982.pdf\n",
            "Saving a041p039.pdf to a041p039.pdf\n",
            "Saving 831770WP0P11260ES003000Fish0to02030.pdf to 831770WP0P11260ES003000Fish0to02030.pdf\n",
            "Saved uploaded file: uploaded_pdfs/animals-13-01250.pdf\n",
            "Saved uploaded file: uploaded_pdfs/biology-12-00092.pdf\n",
            "Saved uploaded file: uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201 (1).pdf\n",
            "Saved uploaded file: uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201.pdf\n",
            "Saved uploaded file: uploaded_pdfs/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.pdf\n",
            "Saved uploaded file: uploaded_pdfs/fcell-07-00013.pdf\n",
            "Saved uploaded file: uploaded_pdfs/fgene-14-1183637.pdf\n",
            "Saved uploaded file: uploaded_pdfs/Fish_2020_Bioinspir._Biomim._15_060401.pdf\n",
            "Saved uploaded file: uploaded_pdfs/fmars-09-924475.pdf\n",
            "Saved uploaded file: uploaded_pdfs/fmicb-12-567408.pdf\n",
            "Saved uploaded file: uploaded_pdfs/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.pdf\n",
            "Saved uploaded file: uploaded_pdfs/Genome Res.-2015-Varshney-1030-42.pdf\n",
            "Saved uploaded file: uploaded_pdfs/ieam1530.pdf\n",
            "Saved uploaded file: uploaded_pdfs/ijms-25-09299-v2.pdf\n",
            "Saved uploaded file: uploaded_pdfs/jeb236802.pdf\n",
            "Saved uploaded file: uploaded_pdfs/nclimate1616.pdf\n",
            "Saved uploaded file: uploaded_pdfs/PIIS1534580715000751.pdf\n",
            "Saved uploaded file: uploaded_pdfs/PIIS1534580719308135 (1).pdf\n",
            "Saved uploaded file: uploaded_pdfs/PIIS1534580719308135.pdf\n",
            "Saved uploaded file: uploaded_pdfs/s41467-017-00175-6.pdf\n",
            "Saved uploaded file: uploaded_pdfs/srep08841.pdf\n",
            "Saved uploaded file: uploaded_pdfs/1-s2.0-S1046202316302833-main.pdf\n",
            "Saved uploaded file: uploaded_pdfs/4982.pdf\n",
            "Saved uploaded file: uploaded_pdfs/a041p039.pdf\n",
            "Saved uploaded file: uploaded_pdfs/831770WP0P11260ES003000Fish0to02030.pdf\n",
            "Selected files: ['uploaded_pdfs/animals-13-01250.pdf', 'uploaded_pdfs/biology-12-00092.pdf', 'uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201 (1).pdf', 'uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201.pdf', 'uploaded_pdfs/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.pdf', 'uploaded_pdfs/fcell-07-00013.pdf', 'uploaded_pdfs/fgene-14-1183637.pdf', 'uploaded_pdfs/Fish_2020_Bioinspir._Biomim._15_060401.pdf', 'uploaded_pdfs/fmars-09-924475.pdf', 'uploaded_pdfs/fmicb-12-567408.pdf', 'uploaded_pdfs/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.pdf', 'uploaded_pdfs/Genome Res.-2015-Varshney-1030-42.pdf', 'uploaded_pdfs/ieam1530.pdf', 'uploaded_pdfs/ijms-25-09299-v2.pdf', 'uploaded_pdfs/jeb236802.pdf', 'uploaded_pdfs/nclimate1616.pdf', 'uploaded_pdfs/PIIS1534580715000751.pdf', 'uploaded_pdfs/PIIS1534580719308135 (1).pdf', 'uploaded_pdfs/PIIS1534580719308135.pdf', 'uploaded_pdfs/s41467-017-00175-6.pdf', 'uploaded_pdfs/srep08841.pdf', 'uploaded_pdfs/1-s2.0-S1046202316302833-main.pdf', 'uploaded_pdfs/4982.pdf', 'uploaded_pdfs/a041p039.pdf', 'uploaded_pdfs/831770WP0P11260ES003000Fish0to02030.pdf']\n",
            "Converting uploaded_pdfs/animals-13-01250.pdf to markdown...\n",
            "Markdown text length: 123702\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/animals-13-01250_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/animals-13-01250_pymupdf4llm.md\n",
            "Processing 32 chunks from cleaned_output_20250530_030926/markdown/animals-13-01250_pymupdf4llm.md...\n",
            "Processing chunk 1/32...\n",
            "Processing chunk 2/32...\n",
            "Processing chunk 3/32...\n",
            "Processing chunk 4/32...\n",
            "Processing chunk 5/32...\n",
            "Processing chunk 6/32...\n",
            "Processing chunk 7/32...\n",
            "Processing chunk 8/32...\n",
            "Processing chunk 9/32...\n",
            "Processing chunk 10/32...\n",
            "Processing chunk 11/32...\n",
            "Processing chunk 12/32...\n",
            "Processing chunk 13/32...\n",
            "Processing chunk 14/32...\n",
            "Processing chunk 15/32...\n",
            "Processing chunk 16/32...\n",
            "Processing chunk 17/32...\n",
            "Processing chunk 18/32...\n",
            "Processing chunk 19/32...\n",
            "Processing chunk 20/32...\n",
            "Processing chunk 21/32...\n",
            "Processing chunk 22/32...\n",
            "Processing chunk 23/32...\n",
            "Processing chunk 24/32...\n",
            "Processing chunk 25/32...\n",
            "Processing chunk 26/32...\n",
            "Processing chunk 27/32...\n",
            "Processing chunk 28/32...\n",
            "Processing chunk 29/32...\n",
            "Processing chunk 30/32...\n",
            "Processing chunk 31/32...\n",
            "Processing chunk 32/32...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_animals-13-01250.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/biology-12-00092.pdf to markdown...\n",
            "Markdown text length: 104453\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/biology-12-00092_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/biology-12-00092_pymupdf4llm.md\n",
            "Processing 27 chunks from cleaned_output_20250530_030926/markdown/biology-12-00092_pymupdf4llm.md...\n",
            "Processing chunk 1/27...\n",
            "Processing chunk 2/27...\n",
            "Processing chunk 3/27...\n",
            "Processing chunk 4/27...\n",
            "Processing chunk 5/27...\n",
            "Processing chunk 6/27...\n",
            "Processing chunk 7/27...\n",
            "Processing chunk 8/27...\n",
            "Processing chunk 9/27...\n",
            "Processing chunk 10/27...\n",
            "Processing chunk 11/27...\n",
            "Processing chunk 12/27...\n",
            "Processing chunk 13/27...\n",
            "Processing chunk 14/27...\n",
            "Processing chunk 15/27...\n",
            "Processing chunk 16/27...\n",
            "Processing chunk 17/27...\n",
            "Processing chunk 18/27...\n",
            "Processing chunk 19/27...\n",
            "Processing chunk 20/27...\n",
            "Processing chunk 21/27...\n",
            "Processing chunk 22/27...\n",
            "Processing chunk 23/27...\n",
            "Processing chunk 24/27...\n",
            "Processing chunk 25/27...\n",
            "Processing chunk 26/27...\n",
            "Processing chunk 27/27...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_biology-12-00092.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201 (1).pdf to markdown...\n",
            "Markdown text length: 10441\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201 (1)_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201 (1)_pymupdf4llm.md\n",
            "Processing 3 chunks from cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201 (1)_pymupdf4llm.md...\n",
            "Processing chunk 1/3...\n",
            "Processing chunk 2/3...\n",
            "Processing chunk 3/3...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Blake_2010_Bioinspir._Biomim._5_030201 (1).jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Blake_2010_Bioinspir._Biomim._5_030201.pdf to markdown...\n",
            "Markdown text length: 10441\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201_pymupdf4llm.md\n",
            "Processing 3 chunks from cleaned_output_20250530_030926/markdown/Blake_2010_Bioinspir._Biomim._5_030201_pymupdf4llm.md...\n",
            "Processing chunk 1/3...\n",
            "Processing chunk 2/3...\n",
            "Processing chunk 3/3...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Blake_2010_Bioinspir._Biomim._5_030201.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.pdf to markdown...\n",
            "Markdown text length: 42225\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in_pymupdf4llm.md\n",
            "Processing 11 chunks from cleaned_output_20250530_030926/markdown/Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in_pymupdf4llm.md...\n",
            "Processing chunk 1/11...\n",
            "Processing chunk 2/11...\n",
            "Processing chunk 3/11...\n",
            "Processing chunk 4/11...\n",
            "Processing chunk 5/11...\n",
            "Processing chunk 6/11...\n",
            "Processing chunk 7/11...\n",
            "Processing chunk 8/11...\n",
            "Processing chunk 9/11...\n",
            "Processing chunk 10/11...\n",
            "Processing chunk 11/11...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/fcell-07-00013.pdf to markdown...\n",
            "Markdown text length: 101256\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/fcell-07-00013_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/fcell-07-00013_pymupdf4llm.md\n",
            "Processing 26 chunks from cleaned_output_20250530_030926/markdown/fcell-07-00013_pymupdf4llm.md...\n",
            "Processing chunk 1/26...\n",
            "Processing chunk 2/26...\n",
            "Processing chunk 3/26...\n",
            "Processing chunk 4/26...\n",
            "Processing chunk 5/26...\n",
            "Processing chunk 6/26...\n",
            "Processing chunk 7/26...\n",
            "Processing chunk 8/26...\n",
            "Processing chunk 9/26...\n",
            "Processing chunk 10/26...\n",
            "Processing chunk 11/26...\n",
            "Processing chunk 12/26...\n",
            "Processing chunk 13/26...\n",
            "Processing chunk 14/26...\n",
            "Processing chunk 15/26...\n",
            "Processing chunk 16/26...\n",
            "Processing chunk 17/26...\n",
            "Processing chunk 18/26...\n",
            "Processing chunk 19/26...\n",
            "Processing chunk 20/26...\n",
            "Processing chunk 21/26...\n",
            "Processing chunk 22/26...\n",
            "Processing chunk 23/26...\n",
            "Processing chunk 24/26...\n",
            "Processing chunk 25/26...\n",
            "Processing chunk 26/26...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_fcell-07-00013.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/fgene-14-1183637.pdf to markdown...\n",
            "Markdown text length: 25036\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/fgene-14-1183637_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/fgene-14-1183637_pymupdf4llm.md\n",
            "Processing 7 chunks from cleaned_output_20250530_030926/markdown/fgene-14-1183637_pymupdf4llm.md...\n",
            "Processing chunk 1/7...\n",
            "Processing chunk 2/7...\n",
            "Processing chunk 3/7...\n",
            "Processing chunk 4/7...\n",
            "Processing chunk 5/7...\n",
            "Processing chunk 6/7...\n",
            "Processing chunk 7/7...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_fgene-14-1183637.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Fish_2020_Bioinspir._Biomim._15_060401.pdf to markdown...\n",
            "Markdown text length: 9551\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Fish_2020_Bioinspir._Biomim._15_060401_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Fish_2020_Bioinspir._Biomim._15_060401_pymupdf4llm.md\n",
            "Processing 3 chunks from cleaned_output_20250530_030926/markdown/Fish_2020_Bioinspir._Biomim._15_060401_pymupdf4llm.md...\n",
            "Processing chunk 1/3...\n",
            "Processing chunk 2/3...\n",
            "Processing chunk 3/3...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Fish_2020_Bioinspir._Biomim._15_060401.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/fmars-09-924475.pdf to markdown...\n",
            "Markdown text length: 96822\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/fmars-09-924475_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/fmars-09-924475_pymupdf4llm.md\n",
            "Processing 25 chunks from cleaned_output_20250530_030926/markdown/fmars-09-924475_pymupdf4llm.md...\n",
            "Processing chunk 1/25...\n",
            "Processing chunk 2/25...\n",
            "Processing chunk 3/25...\n",
            "Processing chunk 4/25...\n",
            "Processing chunk 5/25...\n",
            "Processing chunk 6/25...\n",
            "Processing chunk 7/25...\n",
            "Processing chunk 8/25...\n",
            "Processing chunk 9/25...\n",
            "Processing chunk 10/25...\n",
            "Processing chunk 11/25...\n",
            "Processing chunk 12/25...\n",
            "Processing chunk 13/25...\n",
            "Processing chunk 14/25...\n",
            "Processing chunk 15/25...\n",
            "Processing chunk 16/25...\n",
            "Processing chunk 17/25...\n",
            "Processing chunk 18/25...\n",
            "Processing chunk 19/25...\n",
            "Processing chunk 20/25...\n",
            "Processing chunk 21/25...\n",
            "Processing chunk 22/25...\n",
            "Processing chunk 23/25...\n",
            "Processing chunk 24/25...\n",
            "Processing chunk 25/25...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_fmars-09-924475.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/fmicb-12-567408.pdf to markdown...\n",
            "Markdown text length: 157711\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/fmicb-12-567408_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/fmicb-12-567408_pymupdf4llm.md\n",
            "Processing 40 chunks from cleaned_output_20250530_030926/markdown/fmicb-12-567408_pymupdf4llm.md...\n",
            "Processing chunk 1/40...\n",
            "Processing chunk 2/40...\n",
            "Processing chunk 3/40...\n",
            "Processing chunk 4/40...\n",
            "Processing chunk 5/40...\n",
            "Processing chunk 6/40...\n",
            "Processing chunk 7/40...\n",
            "Processing chunk 8/40...\n",
            "Processing chunk 9/40...\n",
            "Processing chunk 10/40...\n",
            "Processing chunk 11/40...\n",
            "Processing chunk 12/40...\n",
            "Processing chunk 13/40...\n",
            "Processing chunk 14/40...\n",
            "Processing chunk 15/40...\n",
            "Processing chunk 16/40...\n",
            "Processing chunk 17/40...\n",
            "Processing chunk 18/40...\n",
            "Processing chunk 19/40...\n",
            "Processing chunk 20/40...\n",
            "Processing chunk 21/40...\n",
            "Processing chunk 22/40...\n",
            "Processing chunk 23/40...\n",
            "Processing chunk 24/40...\n",
            "Processing chunk 25/40...\n",
            "Processing chunk 26/40...\n",
            "Processing chunk 27/40...\n",
            "Processing chunk 28/40...\n",
            "Processing chunk 29/40...\n",
            "Processing chunk 30/40...\n",
            "Processing chunk 31/40...\n",
            "Processing chunk 32/40...\n",
            "Processing chunk 33/40...\n",
            "Processing chunk 34/40...\n",
            "Processing chunk 35/40...\n",
            "Processing chunk 36/40...\n",
            "Processing chunk 37/40...\n",
            "Processing chunk 38/40...\n",
            "Processing chunk 39/40...\n",
            "Processing chunk 40/40...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_fmicb-12-567408.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.pdf to markdown...\n",
            "Markdown text length: 39187\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish_pymupdf4llm.md\n",
            "Processing 10 chunks from cleaned_output_20250530_030926/markdown/Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish_pymupdf4llm.md...\n",
            "Processing chunk 1/10...\n",
            "Processing chunk 2/10...\n",
            "Processing chunk 3/10...\n",
            "Processing chunk 4/10...\n",
            "Processing chunk 5/10...\n",
            "Processing chunk 6/10...\n",
            "Processing chunk 7/10...\n",
            "Processing chunk 8/10...\n",
            "Processing chunk 9/10...\n",
            "Processing chunk 10/10...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/Genome Res.-2015-Varshney-1030-42.pdf to markdown...\n",
            "Markdown text length: 76709\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/Genome Res.-2015-Varshney-1030-42_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/Genome Res.-2015-Varshney-1030-42_pymupdf4llm.md\n",
            "Processing 20 chunks from cleaned_output_20250530_030926/markdown/Genome Res.-2015-Varshney-1030-42_pymupdf4llm.md...\n",
            "Processing chunk 1/20...\n",
            "Processing chunk 2/20...\n",
            "Processing chunk 3/20...\n",
            "Processing chunk 4/20...\n",
            "Processing chunk 5/20...\n",
            "Processing chunk 6/20...\n",
            "Processing chunk 7/20...\n",
            "Processing chunk 8/20...\n",
            "Processing chunk 9/20...\n",
            "Processing chunk 10/20...\n",
            "Processing chunk 11/20...\n",
            "Processing chunk 12/20...\n",
            "Processing chunk 13/20...\n",
            "Processing chunk 14/20...\n",
            "Processing chunk 15/20...\n",
            "Processing chunk 16/20...\n",
            "Processing chunk 17/20...\n",
            "Processing chunk 18/20...\n",
            "Processing chunk 19/20...\n",
            "Processing chunk 20/20...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_Genome Res.-2015-Varshney-1030-42.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/ieam1530.pdf to markdown...\n",
            "Markdown text length: 93269\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/ieam1530_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/ieam1530_pymupdf4llm.md\n",
            "Processing 24 chunks from cleaned_output_20250530_030926/markdown/ieam1530_pymupdf4llm.md...\n",
            "Processing chunk 1/24...\n",
            "Processing chunk 2/24...\n",
            "Processing chunk 3/24...\n",
            "Processing chunk 4/24...\n",
            "Processing chunk 5/24...\n",
            "Processing chunk 6/24...\n",
            "Processing chunk 7/24...\n",
            "Processing chunk 8/24...\n",
            "Processing chunk 9/24...\n",
            "Processing chunk 10/24...\n",
            "Processing chunk 11/24...\n",
            "Processing chunk 12/24...\n",
            "Processing chunk 13/24...\n",
            "Processing chunk 14/24...\n",
            "Processing chunk 15/24...\n",
            "Processing chunk 16/24...\n",
            "Processing chunk 17/24...\n",
            "Processing chunk 18/24...\n",
            "Processing chunk 19/24...\n",
            "Processing chunk 20/24...\n",
            "Processing chunk 21/24...\n",
            "Processing chunk 22/24...\n",
            "Processing chunk 23/24...\n",
            "Processing chunk 24/24...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_ieam1530.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/ijms-25-09299-v2.pdf to markdown...\n",
            "Markdown text length: 107216\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/ijms-25-09299-v2_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/ijms-25-09299-v2_pymupdf4llm.md\n",
            "Processing 28 chunks from cleaned_output_20250530_030926/markdown/ijms-25-09299-v2_pymupdf4llm.md...\n",
            "Processing chunk 1/28...\n",
            "Processing chunk 2/28...\n",
            "Processing chunk 3/28...\n",
            "Processing chunk 4/28...\n",
            "Processing chunk 5/28...\n",
            "Processing chunk 6/28...\n",
            "Processing chunk 7/28...\n",
            "Processing chunk 8/28...\n",
            "Processing chunk 9/28...\n",
            "Processing chunk 10/28...\n",
            "Processing chunk 11/28...\n",
            "Processing chunk 12/28...\n",
            "Processing chunk 13/28...\n",
            "Processing chunk 14/28...\n",
            "Processing chunk 15/28...\n",
            "Processing chunk 16/28...\n",
            "Processing chunk 17/28...\n",
            "Processing chunk 18/28...\n",
            "Processing chunk 19/28...\n",
            "Processing chunk 20/28...\n",
            "Processing chunk 21/28...\n",
            "Processing chunk 22/28...\n",
            "Processing chunk 23/28...\n",
            "Processing chunk 24/28...\n",
            "Processing chunk 25/28...\n",
            "Processing chunk 26/28...\n",
            "Processing chunk 27/28...\n",
            "Processing chunk 28/28...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_ijms-25-09299-v2.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/jeb236802.pdf to markdown...\n",
            "Markdown text length: 189429\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/jeb236802_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/jeb236802_pymupdf4llm.md\n",
            "Processing 49 chunks from cleaned_output_20250530_030926/markdown/jeb236802_pymupdf4llm.md...\n",
            "Processing chunk 1/49...\n",
            "Processing chunk 2/49...\n",
            "Processing chunk 3/49...\n",
            "Processing chunk 4/49...\n",
            "Processing chunk 5/49...\n",
            "Processing chunk 6/49...\n",
            "Processing chunk 7/49...\n",
            "Processing chunk 8/49...\n",
            "Processing chunk 9/49...\n",
            "Processing chunk 10/49...\n",
            "Processing chunk 11/49...\n",
            "Processing chunk 12/49...\n",
            "Processing chunk 13/49...\n",
            "Processing chunk 14/49...\n",
            "Processing chunk 15/49...\n",
            "Processing chunk 16/49...\n",
            "Processing chunk 17/49...\n",
            "Processing chunk 18/49...\n",
            "Processing chunk 19/49...\n",
            "Processing chunk 20/49...\n",
            "Processing chunk 21/49...\n",
            "Processing chunk 22/49...\n",
            "Processing chunk 23/49...\n",
            "Processing chunk 24/49...\n",
            "Processing chunk 25/49...\n",
            "Processing chunk 26/49...\n",
            "Processing chunk 27/49...\n",
            "Processing chunk 28/49...\n",
            "Processing chunk 29/49...\n",
            "Processing chunk 30/49...\n",
            "Processing chunk 31/49...\n",
            "Processing chunk 32/49...\n",
            "Processing chunk 33/49...\n",
            "Processing chunk 34/49...\n",
            "Processing chunk 35/49...\n",
            "Processing chunk 36/49...\n",
            "Processing chunk 37/49...\n",
            "Processing chunk 38/49...\n",
            "Processing chunk 39/49...\n",
            "Processing chunk 40/49...\n",
            "Processing chunk 41/49...\n",
            "Processing chunk 42/49...\n",
            "Processing chunk 43/49...\n",
            "Processing chunk 44/49...\n",
            "Processing chunk 45/49...\n",
            "Processing chunk 46/49...\n",
            "Processing chunk 47/49...\n",
            "Processing chunk 48/49...\n",
            "Processing chunk 49/49...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_jeb236802.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/nclimate1616.pdf to markdown...\n",
            "Markdown text length: 51247\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/nclimate1616_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/nclimate1616_pymupdf4llm.md\n",
            "Processing 13 chunks from cleaned_output_20250530_030926/markdown/nclimate1616_pymupdf4llm.md...\n",
            "Processing chunk 1/13...\n",
            "Processing chunk 2/13...\n",
            "Processing chunk 3/13...\n",
            "Processing chunk 4/13...\n",
            "Processing chunk 5/13...\n",
            "Processing chunk 6/13...\n",
            "Processing chunk 7/13...\n",
            "Processing chunk 8/13...\n",
            "Processing chunk 9/13...\n",
            "Processing chunk 10/13...\n",
            "Processing chunk 11/13...\n",
            "Processing chunk 12/13...\n",
            "Processing chunk 13/13...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_nclimate1616.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/PIIS1534580715000751.pdf to markdown...\n",
            "Markdown text length: 43476\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/PIIS1534580715000751_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/PIIS1534580715000751_pymupdf4llm.md\n",
            "Processing 11 chunks from cleaned_output_20250530_030926/markdown/PIIS1534580715000751_pymupdf4llm.md...\n",
            "Processing chunk 1/11...\n",
            "Processing chunk 2/11...\n",
            "Processing chunk 3/11...\n",
            "Processing chunk 4/11...\n",
            "Processing chunk 5/11...\n",
            "Processing chunk 6/11...\n",
            "Processing chunk 7/11...\n",
            "Processing chunk 8/11...\n",
            "Processing chunk 9/11...\n",
            "Processing chunk 10/11...\n",
            "Processing chunk 11/11...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_PIIS1534580715000751.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/PIIS1534580719308135 (1).pdf to markdown...\n",
            "Markdown text length: 98394\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/PIIS1534580719308135 (1)_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/PIIS1534580719308135 (1)_pymupdf4llm.md\n",
            "Processing 25 chunks from cleaned_output_20250530_030926/markdown/PIIS1534580719308135 (1)_pymupdf4llm.md...\n",
            "Processing chunk 1/25...\n",
            "Processing chunk 2/25...\n",
            "Processing chunk 3/25...\n",
            "Processing chunk 4/25...\n",
            "Processing chunk 5/25...\n",
            "Processing chunk 6/25...\n",
            "Processing chunk 7/25...\n",
            "Processing chunk 8/25...\n",
            "Processing chunk 9/25...\n",
            "Processing chunk 10/25...\n",
            "Processing chunk 11/25...\n",
            "Processing chunk 12/25...\n",
            "Processing chunk 13/25...\n",
            "Processing chunk 14/25...\n",
            "Processing chunk 15/25...\n",
            "Processing chunk 16/25...\n",
            "Processing chunk 17/25...\n",
            "Processing chunk 18/25...\n",
            "Processing chunk 19/25...\n",
            "Processing chunk 20/25...\n",
            "Processing chunk 21/25...\n",
            "Processing chunk 22/25...\n",
            "Processing chunk 23/25...\n",
            "Processing chunk 24/25...\n",
            "Processing chunk 25/25...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_PIIS1534580719308135 (1).jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/PIIS1534580719308135.pdf to markdown...\n",
            "Markdown text length: 98394\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/PIIS1534580719308135_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/PIIS1534580719308135_pymupdf4llm.md\n",
            "Processing 25 chunks from cleaned_output_20250530_030926/markdown/PIIS1534580719308135_pymupdf4llm.md...\n",
            "Processing chunk 1/25...\n",
            "Processing chunk 2/25...\n",
            "Processing chunk 3/25...\n",
            "Processing chunk 4/25...\n",
            "Processing chunk 5/25...\n",
            "Processing chunk 6/25...\n",
            "Processing chunk 7/25...\n",
            "Processing chunk 8/25...\n",
            "Processing chunk 9/25...\n",
            "Processing chunk 10/25...\n",
            "Processing chunk 11/25...\n",
            "Processing chunk 12/25...\n",
            "Processing chunk 13/25...\n",
            "Processing chunk 14/25...\n",
            "Processing chunk 15/25...\n",
            "Processing chunk 16/25...\n",
            "Processing chunk 17/25...\n",
            "Processing chunk 18/25...\n",
            "Processing chunk 19/25...\n",
            "Processing chunk 20/25...\n",
            "Processing chunk 21/25...\n",
            "Processing chunk 22/25...\n",
            "Processing chunk 23/25...\n",
            "Processing chunk 24/25...\n",
            "Processing chunk 25/25...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_PIIS1534580719308135.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/s41467-017-00175-6.pdf to markdown...\n",
            "Markdown text length: 24990\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/s41467-017-00175-6_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/s41467-017-00175-6_pymupdf4llm.md\n",
            "Processing 7 chunks from cleaned_output_20250530_030926/markdown/s41467-017-00175-6_pymupdf4llm.md...\n",
            "Processing chunk 1/7...\n",
            "Processing chunk 2/7...\n",
            "Processing chunk 3/7...\n",
            "Processing chunk 4/7...\n",
            "Processing chunk 5/7...\n",
            "Processing chunk 6/7...\n",
            "Processing chunk 7/7...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_s41467-017-00175-6.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/srep08841.pdf to markdown...\n",
            "Markdown text length: 33425\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/srep08841_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/srep08841_pymupdf4llm.md\n",
            "Processing 9 chunks from cleaned_output_20250530_030926/markdown/srep08841_pymupdf4llm.md...\n",
            "Processing chunk 1/9...\n",
            "Processing chunk 2/9...\n",
            "Processing chunk 3/9...\n",
            "Processing chunk 4/9...\n",
            "Processing chunk 5/9...\n",
            "Processing chunk 6/9...\n",
            "Processing chunk 7/9...\n",
            "Processing chunk 8/9...\n",
            "Processing chunk 9/9...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_srep08841.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/1-s2.0-S1046202316302833-main.pdf to markdown...\n",
            "Markdown text length: 56462\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/1-s2.0-S1046202316302833-main_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/1-s2.0-S1046202316302833-main_pymupdf4llm.md\n",
            "Processing 16 chunks from cleaned_output_20250530_030926/markdown/1-s2.0-S1046202316302833-main_pymupdf4llm.md...\n",
            "Processing chunk 1/16...\n",
            "Processing chunk 2/16...\n",
            "Processing chunk 3/16...\n",
            "Processing chunk 4/16...\n",
            "Processing chunk 5/16...\n",
            "Processing chunk 6/16...\n",
            "Processing chunk 7/16...\n",
            "Processing chunk 8/16...\n",
            "Processing chunk 9/16...\n",
            "Processing chunk 10/16...\n",
            "Processing chunk 11/16...\n",
            "Processing chunk 12/16...\n",
            "Processing chunk 13/16...\n",
            "Processing chunk 14/16...\n",
            "Processing chunk 15/16...\n",
            "Processing chunk 16/16...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_1-s2.0-S1046202316302833-main.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/4982.pdf to markdown...\n",
            "Markdown text length: 30649\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/4982_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/4982_pymupdf4llm.md\n",
            "Processing 8 chunks from cleaned_output_20250530_030926/markdown/4982_pymupdf4llm.md...\n",
            "Processing chunk 1/8...\n",
            "Processing chunk 2/8...\n",
            "Processing chunk 3/8...\n",
            "Processing chunk 4/8...\n",
            "Processing chunk 5/8...\n",
            "Processing chunk 6/8...\n",
            "Processing chunk 7/8...\n",
            "Processing chunk 8/8...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_4982.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/a041p039.pdf to markdown...\n",
            "Markdown text length: 48832\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/a041p039_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/a041p039_pymupdf4llm.md\n",
            "Processing 13 chunks from cleaned_output_20250530_030926/markdown/a041p039_pymupdf4llm.md...\n",
            "Processing chunk 1/13...\n",
            "Processing chunk 2/13...\n",
            "Processing chunk 3/13...\n",
            "Processing chunk 4/13...\n",
            "Processing chunk 5/13...\n",
            "Processing chunk 6/13...\n",
            "Processing chunk 7/13...\n",
            "Processing chunk 8/13...\n",
            "Processing chunk 9/13...\n",
            "Processing chunk 10/13...\n",
            "Processing chunk 11/13...\n",
            "Processing chunk 12/13...\n",
            "Processing chunk 13/13...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_a041p039.jsonl' in JSONL format.\n",
            "Converting uploaded_pdfs/831770WP0P11260ES003000Fish0to02030.pdf to markdown...\n",
            "Markdown text length: 364547\n",
            "Markdown file saved to cleaned_output_20250530_030926/markdown/831770WP0P11260ES003000Fish0to02030_pymupdf4llm.md\n",
            "\n",
            "Processing file: cleaned_output_20250530_030926/markdown/831770WP0P11260ES003000Fish0to02030_pymupdf4llm.md\n",
            "Processing 92 chunks from cleaned_output_20250530_030926/markdown/831770WP0P11260ES003000Fish0to02030_pymupdf4llm.md...\n",
            "Processing chunk 1/92...\n",
            "Processing chunk 2/92...\n",
            "Processing chunk 3/92...\n",
            "Processing chunk 4/92...\n",
            "Processing chunk 5/92...\n",
            "Processing chunk 6/92...\n",
            "Processing chunk 7/92...\n",
            "Processing chunk 8/92...\n",
            "Processing chunk 9/92...\n",
            "Processing chunk 10/92...\n",
            "Processing chunk 11/92...\n",
            "Processing chunk 12/92...\n",
            "Processing chunk 13/92...\n",
            "Processing chunk 14/92...\n",
            "Processing chunk 15/92...\n",
            "Processing chunk 16/92...\n",
            "Processing chunk 17/92...\n",
            "Processing chunk 18/92...\n",
            "Processing chunk 19/92...\n",
            "Processing chunk 20/92...\n",
            "Processing chunk 21/92...\n",
            "Processing chunk 22/92...\n",
            "Processing chunk 23/92...\n",
            "Processing chunk 24/92...\n",
            "Processing chunk 25/92...\n",
            "Processing chunk 26/92...\n",
            "Processing chunk 27/92...\n",
            "Processing chunk 28/92...\n",
            "Processing chunk 29/92...\n",
            "Processing chunk 30/92...\n",
            "Processing chunk 31/92...\n",
            "Processing chunk 32/92...\n",
            "Processing chunk 33/92...\n",
            "Processing chunk 34/92...\n",
            "Processing chunk 35/92...\n",
            "Processing chunk 36/92...\n",
            "Processing chunk 37/92...\n",
            "Processing chunk 38/92...\n",
            "Processing chunk 39/92...\n",
            "Processing chunk 40/92...\n",
            "Processing chunk 41/92...\n",
            "Processing chunk 42/92...\n",
            "Processing chunk 43/92...\n",
            "Processing chunk 44/92...\n",
            "Processing chunk 45/92...\n",
            "Processing chunk 46/92...\n",
            "Processing chunk 47/92...\n",
            "Processing chunk 48/92...\n",
            "Processing chunk 49/92...\n",
            "Processing chunk 50/92...\n",
            "Processing chunk 51/92...\n",
            "Processing chunk 52/92...\n",
            "Processing chunk 53/92...\n",
            "Processing chunk 54/92...\n",
            "Processing chunk 55/92...\n",
            "Processing chunk 56/92...\n",
            "Processing chunk 57/92...\n",
            "Processing chunk 58/92...\n",
            "Processing chunk 59/92...\n",
            "Processing chunk 60/92...\n",
            "Processing chunk 61/92...\n",
            "Processing chunk 62/92...\n",
            "Processing chunk 63/92...\n",
            "Processing chunk 64/92...\n",
            "Processing chunk 65/92...\n",
            "Processing chunk 66/92...\n",
            "Processing chunk 67/92...\n",
            "Processing chunk 68/92...\n",
            "Processing chunk 69/92...\n",
            "Processing chunk 70/92...\n",
            "Processing chunk 71/92...\n",
            "Processing chunk 72/92...\n",
            "Processing chunk 73/92...\n",
            "Processing chunk 74/92...\n",
            "Processing chunk 75/92...\n",
            "Processing chunk 76/92...\n",
            "Processing chunk 77/92...\n",
            "Processing chunk 78/92...\n",
            "Processing chunk 79/92...\n",
            "Processing chunk 80/92...\n",
            "Processing chunk 81/92...\n",
            "Processing chunk 82/92...\n",
            "Processing chunk 83/92...\n",
            "Processing chunk 84/92...\n",
            "Processing chunk 85/92...\n",
            "Processing chunk 86/92...\n",
            "Processing chunk 87/92...\n",
            "Processing chunk 88/92...\n",
            "Processing chunk 89/92...\n",
            "Processing chunk 90/92...\n",
            "Processing chunk 91/92...\n",
            "Processing chunk 92/92...\n",
            "Cleaned content saved to 'cleaned_output_20250530_030926/jsonl/cleaned_831770WP0P11260ES003000Fish0to02030.jsonl' in JSONL format.\n",
            "\n",
            "Copying files to download directory: downloads/processed_jsonl_20250530_030926\n",
            "Files prepared for download in: downloads/processed_jsonl_20250530_030926\n",
            "\n",
            "Offering files for download:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1591a96b-18a0-488f-836a-8689865061f1\", \"cleaned_animals-13-01250.jsonl\", 96774)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_animals-13-01250.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da4e42df-efa2-4d2c-9359-71c29dccab8e\", \"cleaned_srep08841.jsonl\", 22435)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_srep08841.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4c1b2934-8ec5-4225-85b2-ca0d258210a7\", \"cleaned_1-s2.0-S1046202316302833-main.jsonl\", 35697)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_1-s2.0-S1046202316302833-main.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23122e89-0178-437d-bdbe-a7286bbc408d\", \"cleaned_fcell-07-00013.jsonl\", 55769)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_fcell-07-00013.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_00247643-3046-419d-8d52-fdd4ca276d71\", \"cleaned_biology-12-00092.jsonl\", 86255)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_biology-12-00092.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_14b3f38e-503b-4dda-a577-22a6a8e7ef35\", \"cleaned_Fish_2020_Bioinspir._Biomim._15_060401.jsonl\", 5078)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Fish_2020_Bioinspir._Biomim._15_060401.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3903226c-1b2b-4424-998d-7b7f6ca4ecfc\", \"cleaned_ieam1530.jsonl\", 74294)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_ieam1530.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60360bbc-ca09-4fe9-9a2e-6b014efffa39\", \"cleaned_ijms-25-09299-v2.jsonl\", 111686)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_ijms-25-09299-v2.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd3e11fe-3d5d-43dd-9e2d-be6d6a117658\", \"cleaned_Blake_2010_Bioinspir._Biomim._5_030201.jsonl\", 7120)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Blake_2010_Bioinspir._Biomim._5_030201.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_94dedc8a-c167-48bd-af9a-df65048ede69\", \"cleaned_PIIS1534580715000751.jsonl\", 28496)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_PIIS1534580715000751.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93d1ff14-9d39-478e-a64e-d4ea15793a39\", \"cleaned_Blake_2010_Bioinspir._Biomim._5_030201 (1).jsonl\", 7668)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Blake_2010_Bioinspir._Biomim._5_030201 (1).jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d46c9e1c-f579-45a0-8900-e64bf517fa9d\", \"cleaned_Genome Res.-2015-Varshney-1030-42.jsonl\", 53457)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Genome Res.-2015-Varshney-1030-42.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c5ce87be-d6f7-4f84-8fd8-ea4fcde8c44d\", \"cleaned_Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.jsonl\", 28956)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Diversity and Distributions - 2022 - Dong - Biological traits  geographic distributions  and species conservation in.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e4fa83c0-7449-4048-8df4-201977f814d0\", \"cleaned_fgene-14-1183637.jsonl\", 15764)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_fgene-14-1183637.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62bf570f-b9cd-46c8-b2e5-4aa9282731de\", \"cleaned_PIIS1534580719308135.jsonl\", 54605)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_PIIS1534580719308135.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f559a46-d05f-40cf-b751-c4951843d313\", \"cleaned_s41467-017-00175-6.jsonl\", 16761)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_s41467-017-00175-6.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1bf5f57d-3978-4c4d-bf35-8029f930ac20\", \"cleaned_831770WP0P11260ES003000Fish0to02030.jsonl\", 259342)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_831770WP0P11260ES003000Fish0to02030.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_80040d9f-b2f6-4ee1-b76a-dc4a1fdfe2b7\", \"cleaned_4982.jsonl\", 17658)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_4982.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3bfb6cf7-c127-4e32-822a-7c5c63d48bf4\", \"cleaned_fmars-09-924475.jsonl\", 67761)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_fmars-09-924475.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f44d9cb7-44bf-4c7f-b045-83b589d5f1b5\", \"cleaned_Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.jsonl\", 25183)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_Genes to Cells - 2014 - Ota - Multiple genome modifications by the CRISPR Cas9 system in zebrafish.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1278785a-3601-427d-b0b2-1a16c15fd857\", \"cleaned_nclimate1616.jsonl\", 37530)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_nclimate1616.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_13c4fc38-3f7a-416c-af6e-d3c4482880a3\", \"cleaned_a041p039.jsonl\", 36070)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_a041p039.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9096af9c-19d5-4afd-9dba-94f0793e8e70\", \"cleaned_jeb236802.jsonl\", 126114)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_jeb236802.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_107b28bb-f5b8-4b19-98d1-c17e8450c8c9\", \"cleaned_fmicb-12-567408.jsonl\", 112144)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_fmicb-12-567408.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fcd68dd-0cd0-4afa-9e5d-1d0423764ab4\", \"cleaned_PIIS1534580719308135 (1).jsonl\", 56070)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Downloaded cleaned_PIIS1534580719308135 (1).jsonl\n"
          ]
        }
      ]
    }
  ]
}